{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build project description \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project keywords\n",
    "project_keywords = \"\"\"The PCIe Lane Margining. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to access the openAI API, you need an API key which you can get it from  https://platform.openai.com/api-keys\n",
    "once you have a key then you can either save it as an environment variable or hard code in as needed from simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import openai\n",
    "\n",
    "import streamlit as st\n",
    "from decouple import config\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load the OpenAI API key from the environment variables\n",
    "try:\n",
    "    load_dotenv(override=True)\n",
    "    # os.environ[\"OPENAI_API_KEY\"] = \"your key\"\n",
    "    openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if not openai.api_key:\n",
    "        raise ValueError(\"OPENAI_API_KEY is not set in the environment variables.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading environment variables or setting OpenAI API key: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openAI model name\n",
    "# https://platform.openai.com/docs/models\n",
    "#openAI_model=\"gpt-4\"\n",
    "#openAI_model=\"gpt-4-32k\"\n",
    "#openAI_model=\"gpt-4-turbo\"\n",
    "openAI_model=\"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "try:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"chat_history\", \"question\"],\n",
    "        template=\"\"\"You are technical writer who has a high level of experience in technical communication, create instruction manuals, how-to guides, journal articles, \n",
    "        and other documents to communicate complex information.  you should write technical article by following best practices and guidelines.\n",
    "        - You need to be able to take complex ideas and explain them in a way that is easy to understand.\n",
    "        - You need to create outlines and summaries of your own documents or for giving instructions to the documentation team.\n",
    "        - You need to be able to use a consistent style throughout your documents.\n",
    "        - you need to check grammar and spelling and make sure the document is easy to read and navigate.\n",
    "        - you need to use headings and subheadings to make the document easy to read and navigate.\n",
    "        - for each section, complete paragraph with detailed explaination.  add example if possible.\n",
    "        - if you don't have enough context to answer the question, ask for more information.\n",
    "        Your flow of writing should ensure that the content is structured in a clear, coherent, and comprehensive manner. \n",
    "        Start with the foundational aspects or concepts, then gradually introduce more advanced topics or nuances, \n",
    "        ensuring a smooth transition between sections. Provide a clear introduction and conclusion to the topic.\n",
    "        Make it easy for reader to read with widely used article format and structure.\n",
    "        \n",
    "        chat_history: {chat_history}\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Answer:\"\"\"\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model_name=openAI_model)\n",
    "\n",
    "    memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=4)\n",
    "    llm_chain = LLMChain(\n",
    "        llm=llm,\n",
    "        memory=memory,\n",
    "        prompt=prompt\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize ChatOpenAI : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "                {\"role\": \"assistant\", \"content\": \"Hello there\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"explain following : \" + project_keywords\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "ai_response = llm_chain.predict(question=user_prompt)\n",
    "messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "\n",
    "print(ai_response)\n",
    "\n",
    "project_description = ai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate project description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_description=\"\"\"Write a compelling product description that can capture the interest of potential customers and conveying the value of your product. \n",
    "highlight key features and list important features of the product and focus on how these features benefit the user.\n",
    "The product description should be clear, concise, and engaging, and should provide all the information that a potential customer needs to make an informed decision.\n",
    "\"\"\"\n",
    "    \n",
    "user_prompt = \"write product description according to the task for the project. \" \\\n",
    "    + \"\\n\" + \"task: \" + task_description \\\n",
    "    + \"\\n\" + \"project: \" + project_description\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "ai_response = llm_chain.predict(question=user_prompt)\n",
    "messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "\n",
    "print(ai_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
